{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10075348,"sourceType":"datasetVersion","datasetId":6210519}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artificial Neural Networks and Deep Learning\n\n---\n\n## Homework 2: U-Net\n","metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Import Libraries","metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nseed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\nprint(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"id":"CO6_Ft_8T56A","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:36.839296Z","iopub.execute_input":"2024-12-03T15:12:36.840346Z","iopub.status.idle":"2024-12-03T15:12:36.871780Z","shell.execute_reply.started":"2024-12-03T15:12:36.840309Z","shell.execute_reply":"2024-12-03T15:12:36.870771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚è≥ Load the Data","metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/clean-dataset/clean_dataset.npz\")\n\nX_train = data[\"images\"]\ny_train = data[\"labels\"]\nX_test = data[\"test_set\"]\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","metadata":{"id":"pLaoDaG1V1Yg","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:36.877124Z","iopub.execute_input":"2024-12-03T15:12:36.877465Z","iopub.status.idle":"2024-12-03T15:12:38.275803Z","shell.execute_reply.started":"2024-12-03T15:12:36.877413Z","shell.execute_reply":"2024-12-03T15:12:38.274738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting the dataset 80/20 (training and validation)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=seed\n)\n\n#Display the resulting shapes\nprint(f\"Training images shape: {X_train.shape}, Validation images shape: {X_val.shape}\")\nprint(f\"Training masks shape: {y_train.shape}, Validation masks shape: {y_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:38.276817Z","iopub.execute_input":"2024-12-03T15:12:38.277068Z","iopub.status.idle":"2024-12-03T15:12:38.382801Z","shell.execute_reply.started":"2024-12-03T15:12:38.277043Z","shell.execute_reply":"2024-12-03T15:12:38.381737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add color channel and rescale pixels between 0 and 1\nX_train = X_train[..., np.newaxis] / 255.0\nX_val = X_val[..., np.newaxis] / 255.0\nX_test = X_test[..., np.newaxis] / 255.0\n\n# Retrieve the shape of the input\ninput_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_train))\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:38.384318Z","iopub.execute_input":"2024-12-03T15:12:38.384762Z","iopub.status.idle":"2024-12-03T15:12:39.148524Z","shell.execute_reply.started":"2024-12-03T15:12:38.384687Z","shell.execute_reply":"2024-12-03T15:12:39.147570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üõ†Ô∏è Train and Save the Model","metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":"# Define hyperparameters\nepochs = 200\nbatch_size = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.151386Z","iopub.execute_input":"2024-12-03T15:12:39.151780Z","iopub.status.idle":"2024-12-03T15:12:39.156183Z","shell.execute_reply.started":"2024-12-03T15:12:39.151739Z","shell.execute_reply":"2024-12-03T15:12:39.155191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define callbacks\n# Early stopping to stop the training when val_accuracy stop to increase\nearly_stopping = tfk.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    mode='max',\n    patience=70,\n    restore_best_weights=True,\n    start_from_epoch=50\n)\n\n# Reduce LR when val_loss stop to decrease to avoid local minumum\nreduce_lr_on_plateau = tfk.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.7,\n    patience=15\n)\n\ncallbacks = [early_stopping, reduce_lr_on_plateau]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.157146Z","iopub.execute_input":"2024-12-03T15:12:39.157381Z","iopub.status.idle":"2024-12-03T15:12:39.170525Z","shell.execute_reply.started":"2024-12-03T15:12:39.157357Z","shell.execute_reply":"2024-12-03T15:12:39.169770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n    # Initialise the input tensor\n    x = input_tensor\n\n    # Apply a sequence of Conv2D, Batch Normalisation and Activation layers for the specified number of stacks\n    for i in range(stack):\n        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n\n    # Return the transformed tensor\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.171661Z","iopub.execute_input":"2024-12-03T15:12:39.172015Z","iopub.status.idle":"2024-12-03T15:12:39.184375Z","shell.execute_reply.started":"2024-12-03T15:12:39.171988Z","shell.execute_reply":"2024-12-03T15:12:39.183622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_unet_model(input_shape=(64, 128, 3), num_classes=num_classes, seed=seed):\n    tf.random.set_seed(seed)\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n\n    # Downsampling path\n    down_block_1 = unet_block(input_layer, 64, name='down_block1_')\n    d1 = tfkl.MaxPooling2D()(down_block_1)\n\n    down_block_2 = unet_block(d1, 128, name='down_block2_')\n    d2 = tfkl.MaxPooling2D()(down_block_2)\n\n    down_block_3 = unet_block(d2, 256, name='down_block3_')\n    down_block_3 = tfkl.Dropout(0.5)(down_block_3)\n    d3 = tfkl.MaxPooling2D()(down_block_3)\n\n    # Bottleneck\n    bottleneck = unet_block(d3, 512, name='bottleneck')\n    bottleneck = tfkl.Dropout(0.5)(bottleneck)\n    \n    # Upsampling path\n    u3 = tfkl.UpSampling2D()(bottleneck)\n    u3 = tfkl.Concatenate()([u3, down_block_3])\n    u3 = unet_block(u3, 256, name='up_block3_')\n    \n    u2 = tfkl.UpSampling2D()(u3)\n    u2 = tfkl.Concatenate()([u2, down_block_2])\n    u2 = unet_block(u2, 128, name='up_block2_')\n\n    u1 = tfkl.UpSampling2D()(u2)\n    u1 = tfkl.Concatenate()([u1, down_block_1])\n    u1 = unet_block(u1, 64, name='up_block1_')\n\n    # Output Layer\n    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u1)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.185420Z","iopub.execute_input":"2024-12-03T15:12:39.185763Z","iopub.status.idle":"2024-12-03T15:12:39.198532Z","shell.execute_reply.started":"2024-12-03T15:12:39.185703Z","shell.execute_reply":"2024-12-03T15:12:39.197788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define custom Mean Intersection Over Union metric\nclass MeanIntersectionOverUnion(tfk.metrics.MeanIoU):\n    def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n        if labels_to_exclude is None:\n            labels_to_exclude = [0]  # Default to excluding label 0\n        self.labels_to_exclude = labels_to_exclude\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Convert predictions to class labels\n        y_pred = tf.math.argmax(y_pred, axis=-1)\n\n        # Flatten the tensors\n        y_true = tf.reshape(y_true, [-1])\n        y_pred = tf.reshape(y_pred, [-1])\n\n        # Apply mask to exclude specified labels\n        for label in self.labels_to_exclude:\n            mask = tf.not_equal(y_true, label)\n            y_true = tf.boolean_mask(y_true, mask)\n            y_pred = tf.boolean_mask(y_pred, mask)\n\n        # Update the state\n        return super().update_state(y_true, y_pred, sample_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.199941Z","iopub.execute_input":"2024-12-03T15:12:39.200361Z","iopub.status.idle":"2024-12-03T15:12:39.214846Z","shell.execute_reply.started":"2024-12-03T15:12:39.200320Z","shell.execute_reply":"2024-12-03T15:12:39.214061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generalized Dice Loss\ndef generalized_dice_loss(y_true, y_pred):\n    # Ensure predictions are normalized\n    y_pred = tf.keras.backend.clip(y_pred, 1e-7, 1 - 1e-7)\n    \n    # Compute per-class weights\n    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(0, 1, 2))\n    denominator = tf.reduce_sum(y_true + y_pred, axis=(0, 1, 2))\n    weights = 1 / (tf.reduce_sum(y_true, axis=(0, 1, 2)) ** 2 + 1e-6)\n    \n    # Generalized Dice Score\n    dice_score = tf.reduce_sum(weights * numerator) / tf.reduce_sum(weights * denominator)\n    \n    # Loss is 1 - Dice Score\n    return 1 - dice_score\n    \ndef combined_loss(y_true, y_pred, num_classes=5, alpha=0.5, beta=0.5, gamma=0):\n    # Convert y_true to one-hot encoding\n    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)\n    \n    # Exclude the background class (label 0)\n    y_true_one_hot = y_true_one_hot[..., 1:]  # Ignore background in ground truth\n    y_pred = y_pred[..., 1:]  # Ignore background in predictions\n\n    # Ensure predictions are normalized\n    y_pred = tf.keras.backend.clip(y_pred, 1e-7, 1 - 1e-7)\n\n    # 1. Generalized Dice Loss\n    gen_dice_loss = generalized_dice_loss(y_true_one_hot, y_pred)\n    \n    # 2. Focal Loss\n    gamma_focal = 2.0\n    focal_loss = -tf.reduce_mean(\n        tf.reduce_sum(\n            y_true_one_hot * ((1 - y_pred) ** gamma_focal) * tf.math.log(y_pred), axis=-1\n        )\n    )\n    \n    #4. Boundary loss\n    def erosion2d_custom(tensor, d=1):\n            kernel = tf.ones((d, d, tensor.shape[-1]), dtype=tf.float32)  # Create kernel\n            kernel = tf.expand_dims(kernel, axis=-1)  # [d, d, channels, 1]\n            eroded = tf.nn.depthwise_conv2d(\n                input=tensor,\n                filter=kernel,\n                strides=[1, 1, 1, 1],\n                padding=\"SAME\"\n            )\n            return tf.cast(eroded == tf.reduce_sum(kernel), dtype=tf.float32)\n    \n    def boundary_dou_loss(y_true, y_pred, d=1):\n        \n        # Ensure predictions are between 0 and 1\n        y_pred = tf.clip_by_value(y_pred, 0, 1)\n        \n        # Create the boundary mask\n        kernel = tf.ones((d, d, 4), dtype=tf.float32)\n        y_true_eroded = erosion2d_custom(y_true)\n        y_pred_eroded= erosion2d_custom(y_pred)\n    \n        # Boundary regions are the difference between original and eroded masks\n        y_true_boundary = y_true - y_true_eroded\n        y_pred_boundary = y_pred - y_pred_eroded\n    \n        # Calculate Intersection and Union on the boundary\n        intersection = tf.reduce_sum(y_true_boundary * y_pred_boundary, axis=[1, 2])\n        union = tf.reduce_sum(y_true_boundary + y_pred_boundary, axis=[1, 2]) - intersection\n    \n        # Calculate area and circumference for weighting term\n        area = tf.reduce_sum(y_true, axis=[1, 2])\n        circumference = tf.reduce_sum(y_true_boundary, axis=[1, 2])\n    \n        # Compute alpha\n        alpha = 1 - 2 * (circumference / (area + 1e-6))\n        alpha = tf.clip_by_value(alpha, 0, 1)\n    \n        # Compute Boundary DoU loss\n        loss = (union - intersection) / (union - alpha * intersection + 1e-6)\n    \n        # Reduce mean over the batch\n        return tf.reduce_mean(loss)\n\n    boundary_loss = boundary_dou_loss(y_true_one_hot, y_pred)\n    \n    # Combine the losses with weights\n    total_loss = alpha * gen_dice_loss + beta * focal_loss + gamma * boundary_loss\n    \n    return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.216353Z","iopub.execute_input":"2024-12-03T15:12:39.216806Z","iopub.status.idle":"2024-12-03T15:12:39.232419Z","shell.execute_reply.started":"2024-12-03T15:12:39.216764Z","shell.execute_reply":"2024-12-03T15:12:39.231555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_unet_model(input_shape=input_shape, num_classes=num_classes)\n\n# Define the MeanIoU ignoring the background class\nmean_iou = MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0])\noptimizer = tfk.optimizers.AdamW()\n\nmodel.compile(\n    loss=[combined_loss],\n    optimizer=optimizer,\n    metrics=[\"accuracy\", mean_iou]\n)\n\nmodel.summary(expand_nested=True, show_trainable=True)","metadata":{"id":"CBkb3TRF1KJx","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.233509Z","iopub.execute_input":"2024-12-03T15:12:39.233821Z","iopub.status.idle":"2024-12-03T15:12:39.562010Z","shell.execute_reply.started":"2024-12-03T15:12:39.233794Z","shell.execute_reply":"2024-12-03T15:12:39.561216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    X_train, \n    y_train, \n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data = (X_val, y_val),\n    callbacks = callbacks\n).history\n\n# Calculate and print the final validation accuracy\nfinal_val_mean_iou = round(max(history['val_mean_iou'])* 100, 2)\nprint(f'Final validation MEAN iou: {final_val_mean_iou}%')\n\n# Save the trained model to a file with the timestamp included in the filename\ntimestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nmodel_filename = f\"model_{timestep_str}.keras\"\nmodel.save(model_filename)\ndel model\n\nprint(f\"Model saved to {model_filename}\")","metadata":{"id":"pMCbSMQ_-XoH","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:12:39.563267Z","iopub.execute_input":"2024-12-03T15:12:39.563623Z","iopub.status.idle":"2024-12-03T15:32:12.615700Z","shell.execute_reply.started":"2024-12-03T15:12:39.563584Z","shell.execute_reply":"2024-12-03T15:32:12.614572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot and display training and validation loss\nplt.figure(figsize=(18, 3))\nplt.plot(history['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\nplt.plot(history['val_loss'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\nplt.title('Cross Entropy')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()\n\n# Plot and display training and validation accuracy\nplt.figure(figsize=(18, 3))\nplt.plot(history['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\nplt.plot(history['val_accuracy'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\nplt.title('Accuracy')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()\n\n# Plot and display training and validation mean IoU\nplt.figure(figsize=(18, 3))\nplt.plot(history['mean_iou'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\nplt.plot(history['val_mean_iou'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\nplt.title('Mean Intersection over Union')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:12.616880Z","iopub.execute_input":"2024-12-03T15:32:12.617118Z","iopub.status.idle":"2024-12-03T15:32:13.479669Z","shell.execute_reply.started":"2024-12-03T15:32:12.617095Z","shell.execute_reply":"2024-12-03T15:32:13.478802Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä Prepare Your Submission\n\nIn our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n\n","metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":"# If model_filename is not defined, load the most recent model from Google Drive\nif \"model_filename\" not in globals() or model_filename is None:\n    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n    if files:\n        model_filename = files[0]\n    else:\n        raise FileNotFoundError(\"No model files found in the current directory.\")","metadata":{"id":"BU00iEFcYi_X","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:13.483529Z","iopub.execute_input":"2024-12-03T15:32:13.483946Z","iopub.status.idle":"2024-12-03T15:32:13.490619Z","shell.execute_reply.started":"2024-12-03T15:32:13.483903Z","shell.execute_reply":"2024-12-03T15:32:13.489687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tfk.models.load_model(model_filename, compile=False)\nprint(f\"Model loaded from {model_filename}\")","metadata":{"id":"FMIq69eWgRmr","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:13.491664Z","iopub.execute_input":"2024-12-03T15:32:13.491991Z","iopub.status.idle":"2024-12-03T15:32:14.751490Z","shell.execute_reply.started":"2024-12-03T15:32:13.491949Z","shell.execute_reply":"2024-12-03T15:32:14.750488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom compiling due to custom metric MeanIOU defined\n# Compile the model with specified loss, optimizer, and metrics\nmodel.compile(\n    loss=[combined_loss],\n    optimizer=tfk.optimizers.AdamW(),\n    metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0])]\n)\n\npreds = model.predict(X_test)\npreds = np.argmax(preds, axis=-1)\nprint(f\"Predictions shape: {preds.shape}\")","metadata":{"id":"z287uIQ_VGoK","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:14.752921Z","iopub.execute_input":"2024-12-03T15:32:14.753569Z","iopub.status.idle":"2024-12-03T15:32:29.036704Z","shell.execute_reply.started":"2024-12-03T15:32:14.753526Z","shell.execute_reply":"2024-12-03T15:32:29.035767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_samples_to_display = 10  # Adjust as needed\nfor i in range(num_samples_to_display):\n    plt.figure(figsize=(12, 6))\n\n    # Original image\n    plt.subplot(1, 2, 1)\n    plt.imshow(X_test[i].squeeze(), cmap='gray')  # Adjust for RGB if needed\n    plt.title(\"Input Image\")\n    plt.axis('off')\n\n    # Predicted mask\n    plt.subplot(1, 2, 2)\n    plt.imshow(preds[i], cmap='nipy_spectral')  # Colorful mask\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:29.038259Z","iopub.execute_input":"2024-12-03T15:32:29.038547Z","iopub.status.idle":"2024-12-03T15:32:31.055729Z","shell.execute_reply.started":"2024-12-03T15:32:29.038518Z","shell.execute_reply":"2024-12-03T15:32:31.054881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]","metadata":{"id":"SPjMEKqZW5jX","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:31.057188Z","iopub.execute_input":"2024-12-03T15:32:31.057828Z","iopub.status.idle":"2024-12-03T15:32:31.063881Z","shell.execute_reply.started":"2024-12-03T15:32:31.057786Z","shell.execute_reply":"2024-12-03T15:32:31.062974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and download the csv submission file\ntimestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(preds)\nsubmission_df.to_csv(submission_filename, index=False)","metadata":{"id":"s18kX1uDconq","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:31.065252Z","iopub.execute_input":"2024-12-03T15:32:31.065618Z","iopub.status.idle":"2024-12-03T15:32:53.839730Z","shell.execute_reply.started":"2024-12-03T15:32:31.065580Z","shell.execute_reply":"2024-12-03T15:32:53.839078Z"}},"outputs":[],"execution_count":null}]}