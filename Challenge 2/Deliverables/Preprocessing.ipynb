{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Homework 2: Preprocessing\n",
    "This notebook is meant to pre-process the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ⚙️ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:23.052889Z",
     "iopub.status.busy": "2024-11-29T16:11:23.052140Z",
     "iopub.status.idle": "2024-11-29T16:11:38.633276Z",
     "shell.execute_reply": "2024-11-29T16:11:38.632020Z",
     "shell.execute_reply.started": "2024-11-29T16:11:23.052817Z"
    },
    "id": "CO6_Ft_8T56A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tfk.__version__}\")\n",
    "print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ⏳ Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:38.636714Z",
     "iopub.status.busy": "2024-11-29T16:11:38.635862Z",
     "iopub.status.idle": "2024-11-29T16:11:41.534007Z",
     "shell.execute_reply": "2024-11-29T16:11:41.532722Z",
     "shell.execute_reply.started": "2024-11-29T16:11:38.636655Z"
    },
    "id": "pLaoDaG1V1Yg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"mars_for_students.npz\")\n",
    "\n",
    "training_set = data[\"training_set\"]\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "\n",
    "X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect *X_train* and *y_train* sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:41.535869Z",
     "iopub.status.busy": "2024-11-29T16:11:41.535402Z",
     "iopub.status.idle": "2024-11-29T16:11:44.975865Z",
     "shell.execute_reply": "2024-11-29T16:11:44.974729Z",
     "shell.execute_reply.started": "2024-11-29T16:11:41.535813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a random index to display every time a different set of images\n",
    "X_train_size = X_train.shape[0]\n",
    "random_indices = np.random.randint(0, X_train_size, size = 10)\n",
    "print(random_indices)\n",
    "\n",
    "# Plot the image\n",
    "for index in random_indices:\n",
    "    plt.imshow(X_train[index])\n",
    "    plt.title(index)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(y_train[index])\n",
    "    plt.title(index)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training set, we can understand that **X_train** contains the satellitar images taken from Mars surface, while the **y_train** contains the segmentation masks for the corresponding image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the Outliers\n",
    "Analysing the X_train and y_train sets, it is possible to notice some outliers. For example, there are some pictures (e.g. the one with index 62) contains the picture of an alien. \n",
    "\n",
    "By understanding both the pictures and the masks, the masks seems to be the same even if the alien picture is flipped. So we can scan all the masks that are the same of picture 62 and then remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:44.977431Z",
     "iopub.status.busy": "2024-11-29T16:11:44.977116Z",
     "iopub.status.idle": "2024-11-29T16:11:44.985159Z",
     "shell.execute_reply": "2024-11-29T16:11:44.983030Z",
     "shell.execute_reply.started": "2024-11-29T16:11:44.977400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This function establish if image1 and image2 are the same images, pixel-wise.\n",
    "def are_same(image1, image2):\n",
    "    if image1.shape != image2.shape:\n",
    "        print(\"ERROR: The images are not the same size.\")\n",
    "        return False\n",
    "    return np.array_equal(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:44.989684Z",
     "iopub.status.busy": "2024-11-29T16:11:44.989177Z",
     "iopub.status.idle": "2024-11-29T16:11:45.332757Z",
     "shell.execute_reply": "2024-11-29T16:11:45.331505Z",
     "shell.execute_reply.started": "2024-11-29T16:11:44.989623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show the first picture of an alien\n",
    "first_alien_index = 62\n",
    "alien_indices = []\n",
    "alien_indices.append(first_alien_index)\n",
    "\n",
    "plt.imshow(X_train[first_alien_index])\n",
    "plt.title(first_alien_index)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(y_train[first_alien_index])\n",
    "plt.title(first_alien_index)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:45.334581Z",
     "iopub.status.busy": "2024-11-29T16:11:45.334105Z",
     "iopub.status.idle": "2024-11-29T16:11:45.378747Z",
     "shell.execute_reply": "2024-11-29T16:11:45.377299Z",
     "shell.execute_reply.started": "2024-11-29T16:11:45.334530Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Detect all the images with the same masks as of the first alien\n",
    "for i in range(len(X_train)):\n",
    "    if i != first_alien_index and are_same(y_train[first_alien_index], y_train[i]):\n",
    "        alien_indices.append(i)\n",
    "\n",
    "print(f\"{len(alien_indices)} images have the same mask of the first alien picture:\")\n",
    "print(alien_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:11:45.730785Z",
     "iopub.status.busy": "2024-11-29T16:11:45.729834Z",
     "iopub.status.idle": "2024-11-29T16:11:46.009464Z",
     "shell.execute_reply": "2024-11-29T16:11:46.008138Z",
     "shell.execute_reply.started": "2024-11-29T16:11:45.730721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Delete from X_train and y_train all the images with index in alien_indices\n",
    "X_train = np.delete(X_train, alien_indices, axis=0)\n",
    "y_train = np.delete(y_train, alien_indices, axis=0)\n",
    "\n",
    "print(\"Shape of X_train without aliens: \", X_train.shape)\n",
    "print(\"Shape of y_train without aliens: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated images (that have same image and mask)\n",
    "unique_images_indices = []\n",
    "duplicated_images_indices = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    is_image_unique = True\n",
    "\n",
    "    j = 0\n",
    "    while j < i and is_image_unique:\n",
    "        if are_same(X_train[i], X_train[j]) and y_train[i] == y_train[j]:\n",
    "            print(f\"Image at index {i} already exists at index {j} with same label {y[i]}.\")\n",
    "            is_image_unique = False\n",
    "        j += 1\n",
    "\n",
    "    if is_image_unique:\n",
    "        unique_images_indices.append(i)\n",
    "    else:\n",
    "        duplicated_images_indices.append(i)\n",
    "\n",
    "if(duplicated_images_indices == []):\n",
    "    print(\"There are no duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if there are duplicated images, but we did not find any.\n",
    "We save the cleaned dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of occurrences of each label\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print('Number of occurrences of each label: ')\n",
    "for i in range(unique.size):\n",
    "    print(f'Label {unique[i]}: {counts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dataset is higly unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset 80/20 (training and validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=seed\n",
    ")\n",
    "\n",
    "#Display the resulting shapes\n",
    "print(f\"Training images shape: {X_train.shape}, Validation images shape: {X_val.shape}\")\n",
    "print(f\"Training masks shape: {y_train.shape}, Validation masks shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255.0\n",
    "X_val = X_val[..., np.newaxis] / 255.0\n",
    "X_test = X_test[..., np.newaxis] / 255.0\n",
    "\n",
    "# Retrieve the shape of the input\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['blue', 'green', 'yellow', 'orange', 'red'])\n",
    "\n",
    "vmin, vmax = 0, 4\n",
    "\n",
    "def cut_big_rock(X,y,alpha=1.0):\n",
    "    i=479\n",
    "    plt.imshow(X_train[i])\n",
    "    \n",
    "    plt.show()\n",
    "    plt.imshow(y_train[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "\n",
    "    batch_size, height, width, channel = X.shape  # No channel dimension for grayscale\n",
    "    # Generate CutMix lambda\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    cut_rat = np.sqrt(1.0 - lam)  # Cutout ratio\n",
    "    cut_h = int(height * cut_rat)\n",
    "    cut_w = int(width * cut_rat)\n",
    "    \n",
    "    # Choose cutout position\n",
    "    x1,x2= 80,125\n",
    "    y1,y2= 0, 30\n",
    "    shift_x = x2 - x1\n",
    "    shift_y = y2 - y1\n",
    "    \n",
    "    # Apply CutMix\n",
    "    X_cut = X.copy()\n",
    "    y_cut = y.copy()\n",
    "\n",
    "    for ind in range(len(X_cut)):\n",
    "        rx1 = np.random.randint(0, width-shift_x)\n",
    "        ry1 = np.random.randint(0, height-shift_y)\n",
    "        rx2 = rx1+shift_x\n",
    "        ry2 = ry1+shift_y\n",
    "        X_cut[ind, ry1:ry2, rx1:rx2] = X[i, y1:y2, x1:x2]\n",
    "        y_cut[ind, ry1:ry2, rx1:rx2] = y[i, y1:y2, x1:x2]\n",
    "        \n",
    "    return X_cut, y_cut\n",
    "\n",
    "X_cut_r, y_cut_r = cut_big_rock(X_train, y_train)\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['blue', 'green', 'yellow', 'orange', 'red'])\n",
    "\n",
    "vmin, vmax = 0, 4\n",
    "\n",
    "for i in range(122,124):\n",
    "    plt.imshow(X_cut_r[i])\n",
    "    plt.show()\n",
    "    plt.imshow(y_cut_r[i],cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    plt.savefig(\"oversampled.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean dataset (without outliers)\n",
    "#np.savez_compressed('clean_dataset', images=X_train, labels=y_train, test_set=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_rock_indices = [31, 56, 57, 140, 145, 158, 162, 241, 326, 382, 406, 443, 470, 475, 572, 614, 728, 737, 739, 813, 832, 849, 856, 872, 922, 985, 1026, 1030, 1125, 1162, 1168, 1169, 1182, 1266, 1337, 1443, 1456, 1475, 1491, 1526, 1527, 1544, 1576, 1633, 1684, 1781, 1792, 1883, 1919, 2014, 2055, 2086, 2102, 2111, 2156, 2193, 2199, 2253, 2331, 2351, 2412, 2417, 2498]\n",
    "\n",
    "for index in big_rock_indices:\n",
    "    plt.imshow(X_train[index])\n",
    "    plt.show()\n",
    "    plt.imshow(y_train[index])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6191331,
     "sourceId": 10049005,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
