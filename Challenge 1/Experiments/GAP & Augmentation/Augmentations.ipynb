{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# ANNDL: 1st challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ‚öôÔ∏è Import Libraries\n",
    "Import the libraries needed for the project and fix the seed for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CO6_Ft_8T56A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "input_img_size = 96\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ‚è≥ Load the Data\n",
    "\n",
    "The data are loaded from the filtered, pre-processed data. For more details, see '''Preprocessing.ipynb''' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLaoDaG1V1Yg"
   },
   "outputs": [],
   "source": [
    "filtered_dataset_path = './Preprocessing/balanced_dataset.npz'\n",
    "data = np.load(filtered_dataset_path)\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "\n",
    "# Define a mapping of labels to their corresponding digit names\n",
    "labels = {0:'Basophil', 1:'Eosinophil', 2:'Erythroblast', 3:'Immature granulocytes', 4:'Lymphocyte', 5:'Monocyte', 6:'Neutrophil', 7:'Platelet'}\n",
    "\n",
    "# Save unique labels\n",
    "unique_labels = list(labels.values())\n",
    "\n",
    "# Show the shape of the dataset\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRqkkFrzBQcY"
   },
   "source": [
    "##  ü¶† Process the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkDrFxZGBQcZ"
   },
   "outputs": [],
   "source": [
    "# Display a sample of images from the training-validation dataset\n",
    "num_img = 10\n",
    "random_indices = random.sample(range(len(X)), num_img)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_img, figsize=(input_img_size, input_img_size))\n",
    "\n",
    "# Iterate through the selected number of images\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = axes[i % num_img]\n",
    "    ax.imshow(np.squeeze(X[idx]), vmin=0., vmax=1.)\n",
    "    ax.set_title(labels[y[idx]])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust layout and display the images\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsT4axxUBQca"
   },
   "outputs": [],
   "source": [
    "# Inspect the target\n",
    "print('Counting occurrences of target classes:')\n",
    "print(pd.DataFrame(y, columns=['digit'])['digit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLucbsBU3Jun"
   },
   "outputs": [],
   "source": [
    "# Normalize the data to the range [0, 1] and encode output labels\n",
    "X = (X / 255).astype('float32')\n",
    "y = tfk.utils.to_categorical(y, num_classes=len(unique_labels))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)\n",
    "print(f'Training data shape: {X_train.shape}, Validation data shape: {X_val.shape}')\n",
    "print(f'Training labels shape: {y_train.shape}, Validation labels shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPzBQgMBo4SC"
   },
   "source": [
    "## üîÜ Agumenting the training set\n",
    "We use AutoContrast from the keras library. It enhances contrast adaptively and may help in highlighting subtle differences between cell types without altering structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "GRzF4ltipAY7"
   },
   "outputs": [],
   "source": [
    "# Install and import keras\n",
    "! pip install keras-cv\n",
    "import keras_cv as kcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jllLegAZpDDF"
   },
   "outputs": [],
   "source": [
    "# Implement AutoContrast\n",
    "value_range = [0, 1]\n",
    "autocontrast = kcv.layers.AutoContrast(value_range)\n",
    "contrast_result = autocontrast({'images': X_train, 'labels': y_train})\n",
    "\n",
    "# Show some images\n",
    "num_img = 10\n",
    "random_indices = random.sample(range(len(contrast_result[\"images\"])), num_img)\n",
    "fig, axes = plt.subplots(1, num_img, figsize=(input_img_size, input_img_size))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = axes[i % num_img]\n",
    "    ax.imshow(np.squeeze(contrast_result[\"images\"][idx]), vmin=0., vmax=1.)\n",
    "    # Get the index of the maximum value (representing the predicted class)\n",
    "    label_index = np.argmax(contrast_result[\"labels\"][idx])\n",
    "    ax.set_title(labels[label_index])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIGol7uMwQGb"
   },
   "outputs": [],
   "source": [
    "# Implement RandomSaturation\n",
    "factor = [0, 1]\n",
    "randomsaturation = kcv.layers.RandomSaturation(factor, seed=seed)\n",
    "saturation_result = randomsaturation({'images': X_train, 'labels': y_train})\n",
    "\n",
    "# Show some images\n",
    "num_img = 10\n",
    "random_indices = random.sample(range(len(saturation_result[\"images\"])), num_img)\n",
    "fig, axes = plt.subplots(1, num_img, figsize=(input_img_size, input_img_size))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = axes[i % num_img]\n",
    "    ax.imshow(np.squeeze(saturation_result[\"images\"][idx]), vmin=0., vmax=1.)\n",
    "    # Get the index of the maximum value (representing the predicted class)\n",
    "    label_index = np.argmax(saturation_result[\"labels\"][idx])\n",
    "    ax.set_title(labels[label_index])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "40PdsDx5rj3O"
   },
   "outputs": [],
   "source": [
    "# Add the result of the augmentatation to the original training set\n",
    "X_train = np.concatenate((X_train, contrast_result[\"images\"]), axis=0)\n",
    "y_train = np.concatenate((y_train, contrast_result[\"labels\"]), axis=0)\n",
    "X_train = np.concatenate((X_train, saturation_result[\"images\"]), axis=0)\n",
    "y_train = np.concatenate((y_train, saturation_result[\"labels\"]), axis=0)\n",
    "\n",
    "# Inspect the target\n",
    "print('Counting occurrences of target classes:')\n",
    "y_train_indices = np.argmax(y_train, axis=1) #\n",
    "print(pd.DataFrame(y_train_indices, columns=['digit'])['digit'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## üõ†Ô∏è Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "u42Ilfkq3aCM"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Retrieve input and output shape\n",
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2ItnmAg3kRf"
   },
   "outputs": [],
   "source": [
    "def build_model (\n",
    "    input_shape = input_shape,\n",
    "    output_shape = output_shape,\n",
    "    learning_rate = learning_rate,\n",
    "    dropout_rate = 0.5,\n",
    "    augmentation = None,\n",
    "    flatten = True,\n",
    "    seed = seed):\n",
    "\n",
    "  tf.random.set_seed(seed)\n",
    "  num_filters = 16\n",
    "  default_kernel_size = 3\n",
    "\n",
    "  # Input layer\n",
    "  inputs = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "  # Apply augmentation layers, if specified, and create the first convolutional layer\n",
    "  if augmentation is None:\n",
    "    x = tfkl.Conv2D(filters=num_filters, kernel_size=default_kernel_size, padding='same', activation='relu', name='Conv2D_1')(inputs)\n",
    "  else:\n",
    "    x = augmentation(inputs)\n",
    "    x = tfkl.Conv2D(filters=num_filters, kernel_size=default_kernel_size, padding='same', activation='relu', name='Conv2D_1')(x)\n",
    "  x = tfkl.MaxPooling2D(pool_size=2, name='MaxPooling2D_1')(x)\n",
    "\n",
    "  x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='Conv2D_2')(x)\n",
    "  x = tfkl.ReLU(name='relu2')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp2')(x)\n",
    "\n",
    "  x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='Conv2D_3')(x)\n",
    "  x = tfkl.ReLU(name='relu3')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp3')(x)\n",
    "\n",
    "  x = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', name='Conv2D_4')(x)\n",
    "  x = tfkl.ReLU(name='relu4')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp4')(x)\n",
    "\n",
    "  # Flatten layer\n",
    "  if flatten == True:\n",
    "    x = tfkl.Flatten(name='Flatten')(x)\n",
    "  else:\n",
    "    x = tfkl.GlobalAveragePooling2D(name='GlobalAveragePooling2D')(x)\n",
    "\n",
    "  # Fully connected layers\n",
    "  x = tfkl.Dense(units=128, activation='relu', name='Dense_1')(x)\n",
    "  x = tfkl.Dropout(rate=dropout_rate, name='Dropout1')(x)\n",
    "\n",
    "  x = tfkl.Dense(units=64, activation='relu', name='Dense_2')(x)\n",
    "  x = tfkl.Dropout(rate=dropout_rate, name='Dropout2')(x)\n",
    "\n",
    "  # Output layer\n",
    "  x = tfkl.Dense(units=output_shape, name='Output')(x)\n",
    "  outputs = tfkl.Activation('softmax', name='Activation_Output')(x)\n",
    "\n",
    "  # Create the model\n",
    "  model = tfk.Model(inputs=inputs, outputs=outputs, name='CNN_Model')\n",
    "\n",
    "  # Compile the model\n",
    "  loss = tfk.losses.CategoricalCrossentropy()\n",
    "  optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "  metrics = ['accuracy']\n",
    "  model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yX6-Xb_7xkai"
   },
   "outputs": [],
   "source": [
    "# Define a data augmentation pipeline\n",
    "# Layer performing some geometric operations, that resemble that of the RandAugment\n",
    "# layer (which was too computationally demanding to be used inside the network).\n",
    "augmentation = tf.keras.Sequential ([\n",
    "      tfkl.RandomFlip(mode='horizontal_and_vertical'),\n",
    "      tfkl.RandomBrightness(0.2, value_range=(0,1)),\n",
    "      tfkl.RandomTranslation(0.2,0.2),\n",
    "      tfkl.RandomZoom(0.2),\n",
    "      tfkl.RandomRotation(0.2),\n",
    "      tfkl.RandomContrast(0.2)\n",
    "], name='augment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhAnlYduBQce"
   },
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "patience = 20\n",
    "\n",
    "early_stopping = tfk.callbacks.EarlyStopping (\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RjOUyo2BQcf"
   },
   "outputs": [],
   "source": [
    "# Build the model with specified input and output shapes\n",
    "model = build_model(flatten=False)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# Plot the model architecture\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHebOwY0BQcf"
   },
   "outputs": [],
   "source": [
    "history = model.fit (\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (X_val, y_val),\n",
    "    callbacks = callbacks\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'weights.keras'\n",
    "model.save(model_filename)\n",
    "\n",
    "# Delete the model to free up resources\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8exErcE-rin"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = tfk.models.load_model(model_filename)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "predictions = model.predict(X_val)\n",
    "pred_classes = np.argmax(predictions, axis=-1)\n",
    "true_classes = np.argmax(y_val, axis=-1)\n",
    "cm = confusion_matrix(true_classes, pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm.T, annot=True, fmt='', xticklabels=unique_labels, yticklabels=unique_labels, cmap='Blues')\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3LrBOUIBQcg"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy metrics\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history['loss'], label='Training set', alpha=.3, color='green', linestyle='--')\n",
    "plt.plot(history['val_loss'], label='Validation set', alpha=.8, color='blue')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history['accuracy'], label='Training set', alpha=.3, color='green', linestyle='--')\n",
    "plt.plot(history['val_accuracy'], label='Validation set', alpha=.8, color='blue')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## üìä Prepare Your Submission\n",
    "\n",
    "To prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:\n",
    "\n",
    "```python\n",
    "# file: model.py\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"\n",
    "```\n",
    "\n",
    "The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.\n",
    "\n",
    "‚ùó Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKT4h-9xYwiT"
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the internal state of the model. Note that the __init__\n",
    "        method cannot accept any arguments.\n",
    "\n",
    "        The following is an example loading the weights of a pre-trained\n",
    "        model.\n",
    "        \"\"\"\n",
    "        self.neural_network = tfk.models.load_model('weights.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels corresponding to the input X. Note that X is a numpy\n",
    "        array of shape (n_samples, 96, 96, 3) and the output should be a numpy\n",
    "        array of shape (n_samples,). Therefore, outputs must no be one-hot\n",
    "        encoded.\n",
    "\n",
    "        The following is an example of a prediction from the pre-trained model\n",
    "        loaded in the __init__ method.\n",
    "        \"\"\"\n",
    "        X = X / 255.0\n",
    "        preds = self.neural_network.predict(X)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GN_cpHlSboXV",
    "RNp6pUZuddqC"
   ],
   "gpuType": "T4",
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
